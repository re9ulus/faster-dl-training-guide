#  Как учить Deep Learning модели быстрее

Советы по ускорению тренировок в рамках одной GPU.
Как максимально быстро кормить данные в GPU.

0. Бенчмаркай
Перед тем как начать что-то улучшать, научись это измерять.
Используй профайлеры
Проверяй что тренировка не разваливается, после внесения изменений

1. Достань более быструю GPU
Каким бы образом ты не извращался, допрыгнуть до следующей GPU в модельном ряду, скорее всего, не получится.
Поэтому, если есть возможность достать GPU - доставай.

2. Проверь боттлнеки на чтение данных
- n_workers > 0
- pin_memory=True
- non_blocking=True

2.1 Используй более быстрые ридеры
Для картинок:

3. Убирай синхронизацию
- любые вызовы Tensor.cpu()/to()/numpy() заставляют GPU синхронизироваться.
Выкидывай все ненужные синхронизации.

4. Увеличивай батч-сайз

5. Фиксированный размер батч-сайза
  - тулзы для паковки батч-сайза

6. Benchmark=True

7. AdaptiveMixedPrecision или утилизация тензорных ядер
AdaptiveMixedPrecision позволяет выполнять часть операций в 16bit.
Самый эффективный рецепт улучшения.
Проверяй что тренировка не взрывается. Встречал проблемы с CTC лоссом.

8. Apex

9. jit.Fuse

10. Мелкие хаки
optimizer.zero_grad(set_to_none=True)

11. Гайды по тюнингу производительности